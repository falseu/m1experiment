{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluency Rateを線形重回帰、lasso回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.ExcelFile('main_data_1.xlsx')  #Quantity features and fluency score are in this excel file\n",
    "df = data1.parse('Sheet1') #Explantion for each coloumn is in Sheet explantion\n",
    "y = df.filter([\"FR\"]) #Fluency rating\n",
    "rates = y['FR'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_maximum_possibility(post):\n",
    "    return np.mean(np.max(post, axis=1))\n",
    "\n",
    "def average_post(post):\n",
    "    return np.mean(post, axis=0)\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
    "\n",
    "def kl_divergence_between_fluent(fluent_posts, target_posts):\n",
    "    kl_divs = []\n",
    "    for post in target_posts:\n",
    "        kl_div = [kl_divergence(post, fluent_posts[i]) for i in range(len(fluent_posts))]\n",
    "        kl_divs.append(kl_div)\n",
    "    return np.array(kl_divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quality_features(wsj = 'clean_wsj', n_clusters = 50, native_only = False, print_fluent=True):\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    avg_max_pos = []\n",
    "    avg_posts = []\n",
    "\n",
    "    for uttid in range(1, 101):\n",
    "        post_file_path = 'post/dnn5b_pretrain-dbn_dnn_2000_noise_aug/{}/{}/UTT{}.csv'.format(wsj, n_clusters, uttid)\n",
    "        post_pd = pd.read_csv(post_file_path, header=None)\n",
    "        post = post_pd.to_numpy()\n",
    "        avg_max_pos.append(average_maximum_possibility(post))\n",
    "        avg_posts.append(average_post(post))\n",
    "\n",
    "    df1['average_maximum_possibility'] = avg_max_pos\n",
    "    avg_posts = np.array(avg_posts)\n",
    "\n",
    "    fluent_speaker_idx = np.arange(-10, 1) if native_only else np.where(rates >= 8.0)\n",
    "    if print_fluent:\n",
    "        print('Fluent speakers: ', fluent_speaker_idx)\n",
    "    fluent_posts = avg_posts[fluent_speaker_idx]\n",
    "\n",
    "    kl_divs_fluent = kl_divergence_between_fluent(fluent_posts, avg_posts)\n",
    "    kl_divs_fluent_mean = np.mean(kl_divs_fluent, axis=1)\n",
    "\n",
    "    df1['average_KLdivergence_with_fluent'] = kl_divs_fluent_mean\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_cv(X,y,k,c):\n",
    "    coef = []\n",
    "    r2_train = []\n",
    "    r2_test = []\n",
    "    r2 = []\n",
    "    all_pred = []\n",
    "    all_y = []\n",
    "    kf = KFold(n_splits = k, shuffle = True)\n",
    "    clf = ElasticNet(alpha=0.1,l1_ratio=0.9)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        ss = StandardScaler()\n",
    "        X_train = ss.fit_transform(X_train)\n",
    "        X_test = ss.transform(X_test)\n",
    "        clf.fit(X_train, y_train) \n",
    "        coef.append(clf.coef_)\n",
    "        pred_test = clf.predict(X_test)\n",
    "        r2_train.append(r2_score(y_train, clf.predict(X_train)))\n",
    "        r2_test.append(r2_score(y_test, pred_test))\n",
    "        all_pred.append(pred_test)\n",
    "        all_y.append(y_test.values)\n",
    "        \n",
    "    coef_mean = []\n",
    "    for j in range(c):\n",
    "        coef_j = []\n",
    "        for l in range(k):\n",
    "            coef_j.append(coef[l][j])\n",
    "        coef_mean.append(mean(coef_j))\n",
    "    \n",
    "    from scipy.stats import pearsonr\n",
    "  \n",
    "    correlation, p_value = pearsonr(np.ravel(all_pred), np.ravel(all_y))\n",
    "    \n",
    "    return coef_mean, correlation, p_value, mean(r2_test)\n",
    "\n",
    "def train(X, y, k, c, n_trials = 10, print_current=True):\n",
    "    coef_list = np.zeros((c))\n",
    "    corr_list = []\n",
    "    p_list = []\n",
    "    r2_list = []\n",
    "    for i in range(10):\n",
    "        coef, correlation, p_value, r2_test = elastic_cv(X, y, k, c)\n",
    "        coef_list += np.array(coef)\n",
    "        corr_list.append(correlation)\n",
    "        p_list.append(p_value)\n",
    "        r2_list.append(r2_test)\n",
    "\n",
    "    coef_mean = coef_list / n_trials\n",
    "    correlation = mean(corr_list)\n",
    "    p_value = mean(p_list)\n",
    "    r2_test = mean(r2_list)\n",
    "\n",
    "    if print_current:\n",
    "        print(\"Average 回帰変数\", coef_mean)\n",
    "        print(\"Average 相関係数:\", correlation)\n",
    "        print(\"Average p値:\", p_value)\n",
    "        print('Average r2_test:', r2_test)\n",
    "\n",
    "    return coef_mean, correlation, p_value, r2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 回帰変数 [0.76823905 1.33191602]\n",
      "Average 相関係数: 0.8193963724844843\n",
      "Average p値: 4.31705778494182e-25\n",
      "Average r2_test: 0.6652608144851501\n"
     ]
    }
   ],
   "source": [
    "X_ori = df.filter([\"ATCL_P\",\"phonation_rate\"])\n",
    "_ = train(X_ori, y, 5, 2, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean wsj 50 MAX only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluent speakers:  (array([42, 45, 49, 52, 68, 72, 78, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
      "      dtype=int64),)\n",
      "Average 回帰変数 [0.74965062 1.38998177 0.43771613]\n",
      "Average 相関係数: 0.8513049136968747\n",
      "Average p値: 2.059881298710742e-28\n",
      "Average r2_test: 0.718934100280917\n"
     ]
    }
   ],
   "source": [
    "post_df = compute_quality_features(wsj = 'clean_wsj', n_clusters=50)\n",
    "X_max = post_df.filter([\"ATCL_P\",\"phonation_rate\", \"average_maximum_possibility\"])\n",
    "_ = train(X_max, y, 5, 3, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean wsj 50 KL only, native + fluent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 回帰変数 [ 0.57673893  0.61764616 -1.05979258]\n",
      "Average 相関係数: 0.8844118324671238\n",
      "Average p値: 7.384592324730762e-34\n",
      "Average r2_test: 0.7714799577586595\n"
     ]
    }
   ],
   "source": [
    "X_native_fluent = post_df.filter([\"ATCL_P\",\"phonation_rate\", \\\n",
    "    \"average_KLdivergence_with_fluent\"])\n",
    "_ = train(X_native_fluent, y, 5, 3, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfluent speaker average kl divergence 0.269489501696798\n",
      "Fluent speaker average kl divergence 0.17976784672322937\n"
     ]
    }
   ],
   "source": [
    "kl_list = post_df.filter(['average_KLdivergence_with_fluent']).to_numpy()\n",
    "print(\"Unfluent speaker average kl divergence\", np.mean(kl_list[np.where(rates < 8.0)]))\n",
    "print(\"Fluent speaker average kl divergence\", np.mean(kl_list[np.where(rates >= 8.0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean wsj 50 KL only, native only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluent speakers:  [-10  -9  -8  -7  -6  -5  -4  -3  -2  -1   0]\n",
      "Average 回帰変数 [ 0.54968446  0.75011326 -0.96225617]\n",
      "Average 相関係数: 0.8810404283877226\n",
      "Average p値: 6.604284407792609e-33\n",
      "Average r2_test: 0.7546854116673984\n"
     ]
    }
   ],
   "source": [
    "native_only_df = compute_quality_features(wsj = 'clean_wsj', n_clusters=50, native_only=True)\n",
    "X_native_only = native_only_df.filter([\"ATCL_P\",\"phonation_rate\", \\\n",
    "    \"average_KLdivergence_with_fluent\"])\n",
    "_ = train(X_native_only, y, 5, 3, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean wsj 50 full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 回帰変数 [ 0.57126856  0.70016824  0.3822208  -1.01325073]\n",
      "Average 相関係数: 0.912567102649622\n",
      "Average p値: 1.9576403861146702e-39\n",
      "Average r2_test: 0.8189879096917841\n"
     ]
    }
   ],
   "source": [
    "X_curr = post_df.filter([\"ATCL_P\",\"phonation_rate\", \"average_maximum_possibility\", \\\n",
    "    \"average_KLdivergence_with_fluent\"])\n",
    "_ = train(X_curr, y, 5, 4, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_list = [50, 200, 500, 1000, 2000]\n",
    "corr_list = []\n",
    "r2_list = []\n",
    "for n in cluster_list:\n",
    "    curr_df = compute_quality_features(wsj='clean_wsj', n_clusters=n, print_fluent=False)\n",
    "    X_curr = curr_df.filter([\"ATCL_P\",\"phonation_rate\", \"average_maximum_possibility\",\\\n",
    "         \"average_KLdivergence_with_fluent\"])\n",
    "    _, corr, _, r2_test = train(X_curr, y, 5, 4, n_trials=10, print_current=False)\n",
    "    corr_list.append(corr)\n",
    "    r2_list.append(r2_test)\n",
    "cluster_df = pd.DataFrame({'correlation': corr_list, 'r2_score': r2_list}).set_axis(cluster_list)\n",
    "cluster_df.sort_values(by=['correlation'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark record length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clean_wsj</th>\n",
       "      <td>0.913351</td>\n",
       "      <td>0.818371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_wsj_8</th>\n",
       "      <td>0.910369</td>\n",
       "      <td>0.807543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_wsj_6</th>\n",
       "      <td>0.899786</td>\n",
       "      <td>0.794141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_wsj_4</th>\n",
       "      <td>0.891883</td>\n",
       "      <td>0.772022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             correlation  r2_score\n",
       "clean_wsj       0.913351  0.818371\n",
       "clean_wsj_8     0.910369  0.807543\n",
       "clean_wsj_6     0.899786  0.794141\n",
       "clean_wsj_4     0.891883  0.772022"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj_list = ['clean_wsj', 'clean_wsj_4', 'clean_wsj_6', 'clean_wsj_8']\n",
    "corr_list = []\n",
    "r2_list = []\n",
    "for wsj in wsj_list:\n",
    "    curr_df = compute_quality_features(wsj=wsj, n_clusters=50, print_fluent=False)\n",
    "    X_curr = curr_df.filter([\"ATCL_P\",\"phonation_rate\", \"average_maximum_possibility\",\\\n",
    "         \"average_KLdivergence_with_fluent\"])\n",
    "    _, corr, _, r2_test = train(X_curr, y, 5, 4, n_trials=10, print_current=False)\n",
    "    corr_list.append(corr)\n",
    "    r2_list.append(r2_test)\n",
    "length_df = pd.DataFrame({'correlation': corr_list, 'r2_score': r2_list}).set_axis(wsj_list)\n",
    "length_df.sort_values(by=['correlation'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2499e96b6d0d7fdcc6c339f4902b9c8639e746c081e1007265a219129553f895"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
